{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate, train_test_split, GridSearchCV, ShuffleSplit, learning_curve, validation_curve\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize, MinMaxScaler, LabelEncoder\n",
    "import itertools\n",
    "import timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import dill\n",
    "# # # from dill.settings import settings\n",
    "# dill.dump_session('wilt-nt.db')\n",
    "# # dill.load('done-seiwilt.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# col_names = ['F1', 'F2', 'F3', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_wilt = pd.read_csv('wilt_tr.csv' )\n",
    "\n",
    "print(\"Data has\",len(df_wilt),\"rows and\", len(df_wilt.columns),\"columns.\")\n",
    "if df_wilt.isnull().values.any():\n",
    "    print(\"Data missing\")\n",
    "#df_bankn.head()\n",
    "df_wilt.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_wilt_test = pd.read_csv('wilt_test.csv' )\n",
    "\n",
    "print(\"Data has\",len(df_wilt),\"rows and\", len(df_wilt.columns),\"columns.\")\n",
    "if df_wilt.isnull().values.any():\n",
    "    print(\"Warning: Missing Data\")\n",
    "#df_bankn.head()\n",
    "df_wilt.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_wilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title(\"Wilt Data - Features Correlation\")\n",
    "plt.xlabel('Mean Red')\n",
    "plt.ylabel('Mean Green')\n",
    "plt.scatter(df_wilt['Mean_Red'], df_wilt['Mean_Green'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_wilt['Mean_Red'].corr(df_wilt['Mean_Green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title(\"Counts of Wilt Data Labels\")\n",
    "sns.countplot(df_wilt['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_wilt['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# le = preprocessing.LabelEncoder()\n",
    "# le.fit(df_clean['y'])\n",
    "# #le.transform(df_clean['y'])\n",
    "# df_labels = df_wilt[['seismoacoustic','ghazard']].apply(LabelEncoder().fit_transform)\n",
    "#df_labels.describe()\n",
    "\n",
    "\n",
    "encoder = LabelEncoder().fit(df_wilt['class'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_wilt['class'] = encoder.transform(df_wilt['class'])\n",
    "df_wilt_test['class'] = encoder.transform(df_wilt_test['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# names.insert(0, names.pop(names.index('y')))\n",
    "# df_num = df_clean[names[1:]]\n",
    "# x_scaled = min_max_scaler.fit_transform(df_num)\n",
    "col_names = df_wilt.columns\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_scaled = pd.DataFrame(x_scaled, columns=names[1:])\n",
    "# df_scaled.head()\n",
    "# rem_names = ['genergy', 'gpuls', 'gdenergy',\n",
    "#        'gdpuls', 'nbumps', 'nbumps2', 'nbumps3', 'nbumps4',\n",
    "#        'nbumps5', 'nbumps6', 'nbumps7', 'nbumps89', 'energy', 'maxenergy',\n",
    "#        'class']\n",
    "\n",
    "\n",
    "scalar.fit(df_wilt[col_names[1:]])\n",
    "\n",
    "x_scaled = scalar.transform(df_wilt[col_names[1:]])\n",
    "x_scaled_test = scalar.transform(df_wilt_test[col_names[1:]])\n",
    "\n",
    "# df_sc = pd.DataFrame(x_scaled, columns=col_names[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tr_data():\n",
    "\n",
    "\n",
    "    x = np.array(x_scaled)\n",
    "    y = np.array(df_wilt.values[:,0]).astype('int')\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def get_test_data():\n",
    "\n",
    "\n",
    "    x = np.array(x_scaled_test)\n",
    "    y = np.array(df_wilt_test.values[:,0]).astype('int')\n",
    "\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Not splitting - this file is only for training\n",
    "X_train, y_train = get_tr_data()\n",
    "X_test, y_test = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_clean.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sns.countplot(x='class',data=df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.bincount(y_train), np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(df_wilt['class'])\n",
    "# X_train, X_test, y_train, y_test = train_test_split(np.array(xBk),np.array(yBk), test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ros = RandomOverSampler(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train , y_train = ros.fit_resample( X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.countplot(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling done only to training data. Testing data is still imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sns.countplot(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have successfully loaded and processed both datasets. We are ready to start the ML!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#src: sklearn\n",
    "def pllc(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 20)):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"F1\")\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=-1, train_sizes=train_sizes, scoring='f1')\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    \n",
    "    results ={'sizes':train_sizes,'tr_scores':train_scores_mean, 'val_scores': test_scores_mean, 'title':title}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"g\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def tune_hp(estimator, X_train, y_train, title, param_name,param_range, xlabel,xvals=None, cv=5):\n",
    "\n",
    "    \n",
    "            \n",
    "            \n",
    "    train_scores, val_scores = validation_curve(estimator, X_train, y_train, param_name, \n",
    "                                                 param_range, cv=cv, n_jobs=-1, scoring='f1')\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    #train_scores_std = np.std(train_scores, axis=1)\n",
    "    val_scores_mean = np.mean(val_scores, axis=1)\n",
    "    #test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    if xvals is not None:\n",
    "        param_range=xvals\n",
    "            \n",
    "    plt.grid(True)  \n",
    "    plt.plot(param_range, train_scores_mean, 'o-', color = 'g', label='Train Score')\n",
    "    plt.plot(param_range, val_scores_mean, 'o-', color='r', label='Validation Score')\n",
    "    plt.ylabel('F1')\n",
    "    plt.xlabel(xlabel)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "#     plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ML- DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tune_hp(estimator=DecisionTreeClassifier(random_state=1), X_train= X_train, y_train=y_train, title=\"Hypertunning Decision Min Tree Leaf Size - Wilt Data\",\n",
    "        param_name='min_samples_leaf',param_range=np.arange(1,30,1), xlabel=\"Min Leaf Size\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid_DT = {'min_samples_leaf':np.array([1,2,3]), 'max_depth':np.arange(3,8)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GSTree = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid=param_grid_DT, cv=10, scoring='f1', n_jobs=-1)\n",
    "GSTree.fit(X_train, y_train)\n",
    "max_depth, min_samples_leaf =GSTree.best_params_['max_depth'], GSTree.best_params_['min_samples_leaf']\n",
    "print(\"Tree chosen parameters: \")\n",
    "print(GSTree.best_params_)\n",
    "\n",
    "# Tree Grid Search chosen parameters: \n",
    "# {'min_samples_leaf': 1, 'max_depth': 28}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curve DT- Wilt Data\"\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "\n",
    "estimator =  DecisionTreeClassifier(criterion='gini',max_depth=7, min_samples_leaf= 1, random_state=1)\n",
    "_ , DTLC_results = pllc(estimator, title, X_train, y_train, ylim=None, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "DTLC_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='adam', random_state=1, verbose=10, activation='relu'\n",
    "                    , learning_rate_init=0.01 ,)\n",
    "\n",
    "\n",
    "tune_hp(estimator=mlp, X_train= X_train, y_train=y_train, title=\"NN Hypertunning No. nodes in hidden layer -Wilt Data\",\n",
    "        param_name='hidden_layer_sizes',param_range=[(10,),(40,),(70,),(75,),(80,),(85,),(90,),(100,),(150,) ], \n",
    "        xlabel=\"No. nodes in hidden layer\", xvals=None , cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param_grid_nn = {'learning_rate_init':[0.01,.001, .1]}\n",
    "mlp1 = MLPClassifier(solver='adam',random_state=1, verbose=0,learning_rate_init=.01 , hidden_layer_sizes=(80,), activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GSmlp = GridSearchCV(estimator = mlp1, param_grid=param_grid_nn, cv=5, scoring='f1', n_jobs=-1)\n",
    "# GSmlp.fit(X_train, y_train)\n",
    "# learning_rate_init =GSmlp.best_params_['learning_rate_init']\n",
    "# print(\"Tree Grid Search chosen parameters: \")\n",
    "# print(GSmlp.best_params_)\n",
    "mlp1.fit(X_train, y_train)\n",
    "print(mlp1.loss_curve_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curve NN- Wilt Data\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "\n",
    "# estimator =  MLPClassifier(solver='adam',random_state=1, verbose=10, hidden_layer_sizes=(50,300,),\n",
    "#                           learning_rate_init= 0.01, activation= 'relu')\n",
    "_ , NNLC_results = pllc(mlp1, title, X_train, y_train, ylim=None, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NNLC_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final section for neural network will plot the loss curve for each dataset over the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iters = np.arange(1,len(mlp1.loss_curve_)+1).astype(int)\n",
    "print(iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"NN- Loss Curve - Wilt Data\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.plot(iters, mlp1.loss_curve_, 'o-', markersize=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Boosted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBC = GradientBoostingClassifier( random_state=1)\n",
    "\n",
    "#tuneBoosted(X_train, y_train, X_test, y_test, 10, 1, title=\"N of Estimators: Boosted Tree complexity curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tune_hp(estimator=GBC, X_train= X_train, y_train=y_train, title=\"Hypertunning GradBoosted Tree depth (estimators=100) - Wilt Data\",\n",
    "        param_name='max_depth',param_range=np.linspace(1,10,10).astype('int'), xlabel=\"Max Depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'min_samples_leaf': np.array([1]),\n",
    "              'max_depth': [4],\n",
    "              'n_estimators': np.linspace(50,100,10).round().astype('int')}\n",
    "\n",
    "boost = GridSearchCV(estimator = GBC, param_grid=param_grid, cv=10, n_jobs=-1)\n",
    "boost.fit(X_train, y_train)\n",
    "print(\" best parameters are:\")\n",
    "print(boost.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimator_GB =  GradientBoostingClassifier(max_depth=4 , min_samples_leaf=1 , n_estimators=78,random_state=1,)\n",
    "estimator_GB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = 'Learning Curve for Grad-Boosted- Wilt Data'\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "_ , GBDTLC_results = pllc(estimator_GB, title, X_train, y_train, ylim=None, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GBDTLC_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_st = StandardScaler()\n",
    "scaler_st = scaler_st.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#GBC = GradientBoostingClassifier( random_state=1,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "X_train_sc = scaler_st.transform(X_train)\n",
    "X_test_sc = scaler_st.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tune_hp(estimator=SVC(random_state=1,kernel='rbf', C=15), X_train= X_train_sc, y_train=y_train, title=\"Hypertunning SVM Gamma- Wilt Data\",\n",
    "        param_name='gamma',param_range=[0.05, .1,.2,.3,.4,1], xlabel=\"Gamma\", cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curve SVM- Wilt Data\"\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "\n",
    "estimator =  SVC(random_state=1, kernel='rbf', C=15, gamma=0.2)\n",
    "_ , SVM_results = pllc(estimator, title, X_train_sc, y_train, ylim=None, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SVM_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tune_hp(estimator=KNeighborsClassifier(n_jobs=-1), X_train= X_train, y_train=y_train, title=\"Hypertunning KNN # of neighbors- Wilt Data\",\n",
    "        param_name='n_neighbors',param_range=[1,2,3,4,5,6], xlabel=\"K-neighbors\", cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curve KNN- Wilt Data\"\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "\n",
    "estimator =  KNeighborsClassifier(n_jobs=-1, n_neighbors=1,)\n",
    "_ , KNN_results = pllc(estimator, title, X_train, y_train, ylim=None, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KNN_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparison plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#results = [DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results]\n",
    "\n",
    "def plot_LRs(sizes,DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, title,scr):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training Examples\")\n",
    "    plt.ylabel(\"Model F1 Score\")\n",
    "    plt.plot(sizes, DTLC_results[scr], '-', color=\"r\", label=\"DT\")\n",
    "    plt.plot(sizes, NNLC_results[scr] , '-', color=\"g\", label=\"NN\")\n",
    "    plt.plot(sizes, GBDTLC_results[scr] , '-', color=\"b\", label=\"Grad-Bosted\")\n",
    "    plt.plot(sizes, SVM_results[scr] , '-', color=\"k\", label=\"SVM\")\n",
    "    plt.plot(sizes, KNN_results[scr] , '-', color=\"y\", label=\"KNN\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    #plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_LRs(DTLC_results['sizes'],DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, \"Validation Learning Rates - Wilt Data\",'val_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_LRs(DTLC_results['sizes'],DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, \"Validation Learning Rates - Wilt Data\",'val_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_LRs(DTLC_results['sizes'],DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, \"Training Learning Rates - Wilt Data\",'tr_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_LRs(DTLC_results['sizes'],DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, \"Training Learning Rates - Wilt Data\",'tr_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_LRs(DTLC_results['sizes'],DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, \"Validation Learning Rates - Wilt Data\",'val_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "results = [DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results]\n",
    "\n",
    "print(results)\n",
    "# def plot_LRs(n,DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, title):\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.title(\"Model Learning Rates: \" + title)\n",
    "#     plt.xlabel(\"Training Examples\")\n",
    "#     plt.ylabel(\"F1_macro\")\n",
    "#     plt.plot(n, NNlearn, '-', color=\"b\", label=\"Neural Network\")\n",
    "#     plt.plot(n, SMVlearn, '-', color=\"r\", label=\"SVM\")\n",
    "#     plt.plot(n, kNNlearn, '-', color=\"g\", label=\"kNN\")\n",
    "#     plt.plot(n, DTlearn, '-', color=\"m\", label=\"Decision Tree\")\n",
    "#     plt.plot(n, BTlearn, '-', color=\"k\", label=\"Boosted Tree\")\n",
    "#     plt.legend(loc=\"best\")\n",
    "#     plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing_func(clf,X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end_time = timeit.default_timer()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    start_time = timeit.default_timer()    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    end_time = timeit.default_timer()\n",
    "    pred_time = end_time - start_time\n",
    "    \n",
    "\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    cm = confusion_matrix(y_test,y_pred )\n",
    "    \n",
    "    df_cm = pd.DataFrame(cm, index= ['n', 'w'] , columns= ['n' , 'w'])\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"Model Training Time (s):   \"+\"{:.5f}\".format(training_time))\n",
    "    print(\"Model Prediction Time (s): \"+\"{:.5f}\\n\".format(pred_time))\n",
    "    print(\"F1 Score:  \"+\"{:.2f}\".format(f1))\n",
    "    print(\"Accuracy:  \"+\"{:.2f}\".format(accuracy))\n",
    "\n",
    "    print(\"Precision: \"+\"{:.2f}\".format(precision))\n",
    "    print(\"Recall:  \"+\"{:.2f}\".format(recall))\n",
    "\n",
    "    \n",
    "    sns.heatmap(df_cm,cmap=\"YlGnBu\", annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_DT  = DecisionTreeClassifier(criterion='gini',max_depth=5, min_samples_leaf= 1, random_state=1)\n",
    "f_nn = MLPClassifier(solver='adam',random_state=1, hidden_layer_sizes=(80,),\n",
    "                          learning_rate_init= 0.01, activation= 'relu')\n",
    "f_GBC = GradientBoostingClassifier(max_depth=4 , min_samples_leaf=1 , n_estimators=78,random_state=1,)\n",
    "f_svm = SVC(random_state=1, kernel='rbf', C=15, gamma=0.2)\n",
    "f_KNN = KNeighborsClassifier(n_jobs=-1, n_neighbors=1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pipreqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pipreqs -print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(f_DT,X_train, X_test, y_train\n",
    "                            , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(f_nn,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "testing_func(f_GBC,X_train, X_test, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(f_svm,X_train_sc, X_test_sc, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(f_KNN,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(DecisionTreeClassifier(max_depth=6, min_samples_leaf=3),X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
