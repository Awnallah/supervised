{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate, train_test_split, GridSearchCV, ShuffleSplit, learning_curve, validation_curve\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, auc\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize, MinMaxScaler\n",
    "import itertools\n",
    "import timeit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import dill\n",
    "# # # from dill.settings import settings\n",
    "# dill.dump_session('avila-nt.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Fs = ['F' + str(i) for i in range(1,11) ]\n",
    "#names = ['y' BAAAAAAAD, 'variance', 'skewness', 'curtosis', 'entropy']\n",
    "names = Fs + ['y']\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_avil = pd.read_csv('avila.csv')\n",
    "\n",
    "print(\"Data has\",len(df_avil),\"rows and\", len(df_avil.columns),\"columns.\")\n",
    "if df_avil.isnull().values.any():\n",
    "    print(\"have data missing\")\n",
    "\n",
    "df_avil.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_names = sorted(df_avil.y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_avil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_avil['y'])\n",
    "le.transform(df_avil['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_avil['y'] = le.transform(df_avil['y'])\n",
    "le.inverse_transform(df_avil['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "names.insert(0, names.pop(names.index('y')))\n",
    "df_num = df_avil[names[1:]]\n",
    "x_scaled = min_max_scaler.fit_transform(df_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_scaled = pd.DataFrame(x_scaled, columns=names[1:])\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df_avil = pd.concat([df_avil[names[0]],df_scaled],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_avil.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_avil.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class_names = le.inverse_transform( sorted(df_avil.y.unique()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_avil.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.title('Counts of Avila Labels')\n",
    "\n",
    "sns.countplot(df_avil.y.rename('Labels'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have successfully loaded and processed both datasets. We are ready to start the ML!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#src: sklearn\n",
    "def pllc(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 20)):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"F1-macro\")\n",
    "    \n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=-1, train_sizes=train_sizes, scoring='f1_macro')\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    \n",
    "    results ={'sizes':train_sizes,'tr_scores':train_scores_mean, 'val_scores': test_scores_mean, 'title':title}\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"g\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"r\")\n",
    "    \n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def tune_hp(estimator, X_train, y_train, title, param_name,param_range, xlabel,xvals=None, cv=5):\n",
    "\n",
    "    \n",
    "            \n",
    "            \n",
    "    train_scores, val_scores = validation_curve(estimator, X_train, y_train, param_name, \n",
    "                                                 param_range, cv=cv, n_jobs=-1, scoring='f1_macro')\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    #train_scores_std = np.std(train_scores, axis=1)\n",
    "    val_scores_mean = np.mean(val_scores, axis=1)\n",
    "    #test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    if xvals is not None:\n",
    "        param_range=xvals\n",
    "            \n",
    "    plt.grid(True)  \n",
    "    plt.plot(param_range, train_scores_mean, 'o-', color = 'g', label='Train Score')\n",
    "    plt.plot(param_range, val_scores_mean, 'o-', color='r', label='Validation Score')\n",
    "    plt.ylabel('F1-macro')\n",
    "    plt.xlabel(xlabel)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_cr_data():\n",
    "\n",
    "\n",
    "    x = np.array(df_avil.values[:,1:])\n",
    "    y = np.array(df_avil.values[:,0])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML- DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avX, avY = get_cr_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(avX),np.array(avY), test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tune_hp(estimator=DecisionTreeClassifier(max_depth=15), X_train= X_train, y_train=y_train, title=\"Hypertunning Decision Tree Min Leaf Size - Avila Data\",\n",
    "        param_name='min_samples_leaf',param_range=np.arange(1,20,1), xlabel=\"Min Leaf Size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid_DT = {'min_samples_leaf':np.array([1]), 'max_depth':np.arange(5,30)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GSTree = GridSearchCV(estimator = DecisionTreeClassifier(), param_grid=param_grid_DT, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "GSTree.fit(X_train, y_train)\n",
    "max_depth, min_samples_leaf =GSTree.best_params_['max_depth'], GSTree.best_params_['min_samples_leaf']\n",
    "print(\"Tree chosen parameters: \")\n",
    "print(GSTree.best_params_)\n",
    "\n",
    "# Tree Grid Search chosen parameters: \n",
    "# {'max_depth': 19, 'min_samples_leaf': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curve DT- Avila Data\"\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "\n",
    "estimator =  DecisionTreeClassifier(criterion='gini',max_depth=max_depth, min_samples_leaf= min_samples_leaf, random_state=1)\n",
    "_ , DTLC_results = pllc(estimator, title, X_train, y_train, ylim=None, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "DTLC_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='adam',random_state=1, verbose=10,\n",
    "                    learning_rate_init=.01, hidden_layer_sizes= (100,200,80,) ,)\n",
    "\n",
    "\n",
    "tune_hp(estimator=mlp, X_train= X_train, y_train=y_train, title=\"Hypertunning Neural Network N of nodes in Hidden Layer - Avila Data\",\n",
    "        param_name='activation',param_range=['relu', 'logistic', 'tanh'], \n",
    "        xlabel=\"N of nodes in hidden Layers\", xvals=None )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid_nn = {'learning_rate_init':[0.01,0.1,1]}\n",
    "mlp1 = MLPClassifier(solver='adam',random_state=1, verbose=10, hidden_layer_sizes=(10,200,100,), activation='relu')\n",
    "\n",
    "\n",
    "estimator_nn =  MLPClassifier(solver='adam',random_state=1, verbose=0, hidden_layer_sizes=(100,200,80,),\n",
    "                          learning_rate_init= 0.01, activation= 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GSmlp = GridSearchCV(estimator = mlp1, param_grid=param_grid_nn, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "GSmlp.fit(X_train, y_train)\n",
    "learning_rate_init, activation =GSmlp.best_params_['learning_rate_init'], GSmlp.best_params_['activation']\n",
    "\n",
    "print(GSmlp.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curve NN\"\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "_ , NNLC_results = pllc(estimator_nn, title, X_train, y_train, ylim=None, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NNLC_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final section for neural network will plot the loss curve for each dataset over the iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "estimator_nn.fit(X_train, y_train)\n",
    "loss_iter = estimator_nn.loss_curve_\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"NN Loss Curve- Avila Data\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Log Loss\")\n",
    "plt.plot(loss_iter, 'o-', color=\"g\", markersize=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Boosted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBC = GradientBoostingClassifier( random_state=1,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tune_hp(estimator=GBC, X_train= X_train, y_train=y_train, title=\"Hypertunning GradBoosted Tree Max Depth - Avila Data\",\n",
    "        param_name='max_depth',param_range=np.linspace(1,30,30).astype('int'), xlabel=\"Max Depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'min_samples_leaf': np.array([1]),\n",
    "              'max_depth': np.linspace(3,25,3).round().astype('int'),\n",
    "              'n_estimators': np.linspace(80,300,3).round().astype('int')}\n",
    "\n",
    "boost = GridSearchCV(estimator = GBC, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "boost.fit(X_train, y_train)\n",
    "print(\"Per Hyperparameter tuning, best parameters are:\")\n",
    "print(boost.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = 'Learning Curve for Grad-Boosted- Avila Data'\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=1)\n",
    "\n",
    "estimator =  GradientBoostingClassifier(max_depth=4 , min_samples_leaf=1 , n_estimators=200,random_state=1,)\n",
    "_ , GBDTLC_results = pllc(estimator, title, X_train, y_train, ylim=None, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GBDTLC_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_st = StandardScaler()\n",
    "scaler_st = scaler_st.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#GBC = GradientBoostingClassifier( random_state=1,)\n",
    "X_train_sc = scaler_st.transform(X_train)\n",
    "X_test_sc = scaler_st.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tune_hp(estimator=SVC(random_state=1, kernel='rbf', C=90), X_train= X_train_sc, y_train=y_train, title=\"Hypertunning SVM Gamma value- Avila Data\",\n",
    "        param_name='gamma',param_range=[0.1,0.2,0.3,1], xlabel=\"Gamma\", cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curve SVM- Avila Data\"\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "\n",
    "estimator =  SVC(random_state=1, kernel='rbf', C=80)\n",
    "_ , SVM_results = pllc(estimator, title, X_train_sc, y_train, ylim=None, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SVM_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SVM_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tune_hp(estimator=KNeighborsClassifier(n_jobs=-1), X_train= X_train, y_train=y_train, title=\"Hypertunning KNN # of Neighbors- Avila Data\",\n",
    "        param_name='n_neighbors',param_range=[1,2,3,4,5], xlabel=\"K-neighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title = \"Learning Curve KNN- Avila Data\"\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=1)\n",
    "\n",
    "estimator =  KNeighborsClassifier(n_jobs=-1,n_neighbors=1)\n",
    "_ , KNN_results = pllc(estimator, title, X_train, y_train, ylim=None, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KNN_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#results = [DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results]\n",
    "\n",
    "def plot_LRs(sizes,DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results, title,scr):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training Examples\")\n",
    "    plt.ylabel(\"Model F1 Score\")\n",
    "    plt.plot(sizes, DTLC_results[scr], '-', color=\"r\", label=\"Neural Network\")\n",
    "    plt.plot(sizes, NNLC_results[scr] , '-', color=\"g\", label=\"NN\")\n",
    "    plt.plot(sizes, GBDTLC_results[scr] , '-', color=\"b\", label=\"Grad-Bossted\")\n",
    "    plt.plot(sizes, SVM_results[scr] , '-', color=\"k\", label=\"SVM\")\n",
    "    plt.plot(sizes, KNN_results[scr] , '-', color=\"y\", label=\"KNN\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    #plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_LRs(results[0]['sizes'],results[0], results[1], results[2], results[3], results[4], \"Validation Learning Rates - Avila Data\",'val_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "results = [DTLC_results, NNLC_results, GBDTLC_results, SVM_results, KNN_results]\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing_func(clf,X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    start_time = timeit.default_timer()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end_time = timeit.default_timer()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    start_time = timeit.default_timer()    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    end_time = timeit.default_timer()\n",
    "    pred_time = end_time - start_time\n",
    "    \n",
    "\n",
    "    f1 = f1_score(y_test,y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred, average='macro')\n",
    "    recall = recall_score(y_test,y_pred, average='macro')\n",
    "    cm = confusion_matrix(y_test,y_pred )\n",
    "    \n",
    "    df_cm = pd.DataFrame(cm, index= class_names, columns=class_names)\n",
    "\n",
    "    print(\"Model Training Time (s):   \"+\"{:.5f}\".format(training_time))\n",
    "    print(\"Model Prediction Time (s): \"+\"{:.5f}\\n\".format(pred_time))\n",
    "    print(\"F1 Score:  \"+\"{:.2f}\".format(f1))\n",
    "    print(\"Accuracy:  \"+\"{:.2f}\".format(accuracy))\n",
    "    print(\"Precision: \"+\"{:.2f}\".format(precision))\n",
    "    print(\" Recall: \"+\"{:.2f}\".format(recall))\n",
    "    \n",
    "    print(\"Matrix\")\n",
    "\n",
    "    sns.heatmap(df_cm,cmap=\"YlGnBu\", annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_DT  = DecisionTreeClassifier(criterion='gini',max_depth=24, min_samples_leaf= 1, random_state=1)\n",
    "f_NN = MLPClassifier(solver='adam',random_state=1, verbose=0, hidden_layer_sizes=(100,200,80,),\n",
    "                          learning_rate_init= 0.01, activation= 'relu')\n",
    "\n",
    "f_GBC = GradientBoostingClassifier(max_depth=5 , min_samples_leaf=1 , n_estimators=200,random_state=1,)\n",
    "f_SVM = SVC(random_state=1, kernel='rbf', C=80)\n",
    "f_KNN = KNeighborsClassifier(n_jobs=-1, n_neighbors=1,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(f_DT,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(f_NN,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(f_GBC,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(f_SVM,X_train_sc, X_test_sc, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_func(f_KNN,X_train_sc, X_test_sc, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
